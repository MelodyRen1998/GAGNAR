res_path <- "../../simu_k6/simu_k6/result"
}
load(paste0(res_path, "/sim_res_", idx_design, ".rda"))
# data & para
if (exp_id == 1){
## example 1
load(paste0("./data/data_design_", idx_design, ".RData")) # data
load(paste0("./data/true_para_design_", idx_design, ".RData")) # para
} else {
## example 2 & 3
load(paste0("./data/simu_data_design", idx_design, ".RData")) # data
load(paste0("./data/true_para_design", idx_design, ".RData")) # para
}
NN <- dim(all_simu_dat[[1]][[1]])[2]
# ARI & ACC
best_hs = c()
for (reppp in 1:nsims) {
lpml <- lapply(sim_res[[reppp]], function(each_rep) {each_rep$LPML}) %>% unlist()
best_hs[reppp] <- h[which.max(lpml)]
}
ari_h = c()
acc_h = c()
for (reppp in 1:nsims) {
best_h_idx <- which(h == best_hs[[reppp]])
# cat(best_h_idx, "\t")
model_label = sim_res[[reppp]][[best_h_idx]]$Dahlout$zout
true_label = all_simu_dat[[5]][[reppp]]
ariii = adjustedRandIndex(model_label, true_label)
acc_ = 1 - classError(model_label, true_label)$errorRate
ari_h[reppp] = ariii
acc_h[reppp] = acc_
}
ari_seq[idx_design] = mean(ari_h)
acc_seq[idx_design] = mean(acc_h)
}
}
ari_seq
exp_id = 2
res_path <- paste0("../../simulation_realgraph/simu",idx_design)
load(paste0(res_path, "/sim_res_", idx_design, ".rda"))
idx_design = sce_id + (exp_id - 1)*2
cat(idx_design, "\r")
res_path <- paste0("../../simulation_realgraph/simu",idx_design)
load(paste0(res_path, "/sim_res_", idx_design, ".rda"))
load(paste0("../../data_km/simu_data_design", idx_design, ".RData")) # data
load(paste0("../../data_km/true_para_design", idx_design, ".RData")) # para
NN <- dim(all_simu_dat[[1]][[1]])[2]
# ARI & ACC
best_hs = c()
for (reppp in 1:nsims) {
lpml <- lapply(sim_res[[reppp]], function(each_rep) {each_rep$LPML}) %>% unlist()
best_hs[reppp] <- h[which.max(lpml)]
}
ari_h = c()
acc_h = c()
for (reppp in 1:nsims) {
best_h_idx <- which(h == best_hs[[reppp]])
# cat(best_h_idx, "\t")
model_label = sim_res[[reppp]][[best_h_idx]]$Dahlout$zout
true_label = all_simu_dat[[5]][[reppp]]
ariii = adjustedRandIndex(model_label, true_label)
acc_ = 1 - classError(model_label, true_label)$errorRate
ari_h[reppp] = ariii
acc_h[reppp] = acc_
}
mean(ari_h)
mean(acc_h)
for (exp_id in 1:3) {
for (sce_id in 1:2) {
idx_design = sce_id + (exp_id - 1)*2
cat(idx_design, "\r")
K = ifelse(exp_id == 1, 3, ifelse(exp_id == 2, 5, 6))
# load result
if (exp_id == 1){
res_path <- paste0("../../simulation_pack/result/example1")
} else if (exp_id == 2) {
res_path <- paste0("../../simulation_realgraph/simu",idx_design)
} else if (idx_design == 5) {
res_path <- "../../simu_k6/simu5_k6/"
} else if (idx_design == 6) {
res_path <- "../../simu_k6/simu_k6/result"
}
load(paste0(res_path, "/sim_res_", idx_design, ".rda"))
# data & para
if (exp_id == 1){
## example 1
load(paste0("./data/data_design_", idx_design, ".RData")) # data
load(paste0("./data/true_para_design_", idx_design, ".RData")) # para
} else if (exp_id == 2){
load(paste0("../../data_km/simu_data_design", idx_design, ".RData")) # data
load(paste0("../../data_km/true_para_design", idx_design, ".RData")) # para
} else if (exp_id == 3) {
## example 2 & 3
load(paste0("./data/simu_data_design", idx_design, ".RData")) # data
load(paste0("./data/true_para_design", idx_design, ".RData")) # para
}
NN <- dim(all_simu_dat[[1]][[1]])[2]
# ARI & ACC
best_hs = c()
for (reppp in 1:nsims) {
lpml <- lapply(sim_res[[reppp]], function(each_rep) {each_rep$LPML}) %>% unlist()
best_hs[reppp] <- h[which.max(lpml)]
}
ari_h = c()
acc_h = c()
for (reppp in 1:nsims) {
best_h_idx <- which(h == best_hs[[reppp]])
# cat(best_h_idx, "\t")
model_label = sim_res[[reppp]][[best_h_idx]]$Dahlout$zout
true_label = all_simu_dat[[5]][[reppp]]
ariii = adjustedRandIndex(model_label, true_label)
acc_ = 1 - classError(model_label, true_label)$errorRate
ari_h[reppp] = ariii
acc_h[reppp] = acc_
}
ari_seq[idx_design] = mean(ari_h)
acc_seq[idx_design] = mean(acc_h)
}
}
ari_seq
acc_seq
ari_shuffle
ari_shuffle = numeric(6)
acc_shuffle = numeric(6)
# 打乱标签的结果
nshuffle = 100
for (exp_id in 1:3) {
for (sce_id in 1:2) {
idx_design = sce_id + (exp_id - 1)*2
K = ifelse(exp_id == 1, 3, ifelse(exp_id == 2, 5, 6))
# data & para
if (exp_id == 1){
## example 1
load(paste0("./data/data_design_", idx_design, ".RData")) # data
load(paste0("./data/true_para_design_", idx_design, ".RData")) # para
} else {
## example 2 & 3
load(paste0("./data/simu_data_design", idx_design, ".RData")) # data
load(paste0("./data/true_para_design", idx_design, ".RData")) # para
}
NN <- dim(all_simu_dat[[1]][[1]])[2]
# result
load(paste0("./result/sim_res_shuffle_", idx_design, ".rda"))
# ARI
ari = numeric(nshuffle)
acc_df = numeric(nshuffle)
isim = 1
for (ishuf in 1:nshuffle) {
model_label = sim_res[[ishuf]][[1]]$Dahlout$zout
true_label = all_simu_dat[[5]][[isim]]
ariii = adjustedRandIndex(model_label, true_label)
acc_ = 1 - classError(model_label, true_label)$errorRate
ari[ishuf] = ariii
acc_df[ishuf] = acc_
}
# summary(ari)
ari_shuffle[idx_design] = mean(ari)
acc_shuffle[idx_design] = mean(acc_df)
# par(mfrow = c(3,2))
# boxplot(ari)
# summary(acc_df)
}
}
ari_shuffle
df_aris = data.frame(exp = c(1,1,2,2,3,3),
sce = rep(c(1,2), 3),
ari_seq, ari_shuffle)
df_accs = data.frame(exp = c(1,1,2,2,3,3),
sce = rep(c(1,2), 3),
acc_seq, acc_shuffle)
View(df_aris)
View(df_accs)
write.csv(df_aris, "./report/df_aris.csv", row.names = F)
write.csv(df_accs, "./report/df_accs.csv", row.names = F)
write.csv(round(df_aris, 4), "./report/df_aris.csv", row.names = F)
write.csv(round(df_accs, 4), "./report/df_accs.csv", row.names = F)
setwd("~/Desktop/renyimeng/复旦项目/CNAR/CNAR_Stock_2020/data/raw/股票金融数据2018-2020")
# library packages
library(readxl)
library(data.table)
library(reshape2)
# load functions
source("./realData_func.R")
## 1. 协变量 以2019-12-31数据为例
Z_mat <- fread("./Node_feature_2018_2020/2019_12_31/node_specific_factor.csv")
## 2. 收益率
return_colnames <- as.character(read_excel("WeeklyRt_2018_2020/TRD_Week.xlsx", n_max = 1)[1,])  # 列名
week_ret <- read_excel("WeeklyRt_2018_2020/TRD_Week.xlsx", skip = 2)  # 数据
# rename columns, corresponding to "证券代码,交易周份,周开盘日期,周开盘价,周收盘日期,周收盘价,考虑现金红利再投资的周个股回报率"
colnames(week_ret) <- c("Stkcd", "wk", "Opndt", "Wopnprc", "Clsdt", "Wclsprc", "Wretwd")
# transform the data formats
week_ret$Stkcd = as.numeric(week_ret$Stkcd)
week_ret$Opndt = as.Date(week_ret$Opndt)
week_ret$Clsdt = as.Date(week_ret$Clsdt)
# get week and year of close date
week_ret$year = year(week_ret$Clsdt)
week_ret$week = week(week_ret$Clsdt)
week_ret1 <- week_ret  # copy version
## 3. 共同持股网络信息
sh_colnames <- as.character(read_excel("Shareholder_2018_2020/HLD_Shareholders.xlsx", n_max = 1)[1,])
shareholder <- read_excel("Shareholder_2018_2020/HLD_Shareholders.xlsx", skip = 2)
## 分别对应"证券代码"     "统计截止日期" "股东名称"     "持股排名"     "持股比例(%)"
colnames(shareholder) <- c("Stkcd", "Reptdt", "S0301a", "S0306a", "S0304a")
shareholder$Stkcd = as.numeric(shareholder$Stkcd)
shareholder$Reptdt = as.Date(shareholder$Reptdt)
# 根据不同截止统计时间构建股票网络
dd = unique(shareholder$Reptdt)
stock_netL = list()
dd
i = 1
shareholder_date = shareholder[shareholder$Reptdt==dd[i],]
View(shareholder_date)
stock_gudong = as.matrix(shareholder_date[,c("Stkcd", "S0301a")])
score = rep(1, nrow(stock_gudong))
relation = stock_gudong
id1 = sort(unique(relation[,1]))  # stock name
id2 = sort(unique(relation[,2]))  # gudong name
relation = relation[order(relation[,1], relation[,2]),]                                                          ### reorder A
is.null(score)
D = relation
vid = list(id1,id2)
score = score
M = Matrix(data = 0, nrow = length(vid[[1]]), ncol = length(vid[[2]]))
dim(D)
uidx = match(D[,1], vid[[1]], nomatch = 0)
sidx = match(D[,2], vid[[2]], nomatch = 0)
i = uidx > 0 & sidx > 0
Amat = setM(D = relation, vid = list(id1,id2), score = score)                               ### obtain the sparse adjency matrix
dim(Amat)
View(Amat)
Amat@i
Amat@p
stock_gudongL = getNetStruc(stock_gudong, score = rep(1, nrow(stock_gudong)))
IDs = stock_gudongL$IDs
stock_gudongA = stock_gudongL$Amat
stock_comm = tcrossprod(stock_gudongA) %>% as.matrix()
dim(stock_comm)
library(readr)
gnar_p_values_train12 <- read_csv("~/Desktop/renyimeng/复旦项目/GAGNAR/GAGNAR_code_JBES/case_study/city/report/gnar_p_values_train12.csv")
View(gnar_p_values_train12)
setwd("~/Desktop/renyimeng/复旦项目/GAGNAR/GAGNAR_code_JBES/case_study")
write.csv(round(gnar_p_values_train12, 4), "./city/report/gnar_p_train12_clean.csv")
library(readr)
gnar_p_values <- read_csv("stock/report/gnar_p_values.csv")
View(gnar_p_values)
save(round(gnar_p_values, 4), "./stock/report/gnar_p_clean.csv")
write.csv(round(gnar_p_values, 4), "./stock/report/gnar_p_clean.csv")
setwd("~/Desktop/renyimeng/复旦项目/GAGNAR/GAGNAR_code_JBES/case_study/stock")
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
try(sapply(pkg, require, character.only = TRUE), silent = TRUE)
}
packages <- c("scales", "igraph", "mvtnorm", "MCMCpack", "parallel", "mclust", "plyr", "ggplot2")
ipak(packages)
source("./code/gagnar.R")
source("./code/Dahl.R")
source("./code/LPML_VAR.R")
source("./code/GNAR_code-master/estimator.R")
source("./code/real_estimator.R")
# =========
# load data
# =========
load("./stock_data/Ymat_top.rda")
load("./stock_data/Zmat_top.rda")
load("./stock_data/Adjmat_top.rda")
cat("network density is", sum(adj.mt)/(nrow(adj.mt)^2 - nrow(adj.mt)), "\n")
load("./stock_data/dmat_top.rda")  # d.matrix
Zmat <- scale(Zmat)
train_window = 40
test_window = 6
n_window = 1  # rolling window size
train_start = 1
n_test = 1
flag = TRUE
test_days = NULL
pred_rmse = matrix(0, nrow = 7, ncol = 100)
train_end = train_start + train_window - 1
test_start = train_end
test_end = test_start + test_window
# ===============
# compare with GNAR
# ===============
# ==========
# estimation
# ==========
# 1. split train and test set
Ymat_train <- Ymat[,(train_start:train_end)]
Ymat_test <- Ymat[,(test_start:test_end)]  # use the last of trainset as start point
TT = ncol(Ymat_train)
N = nrow(Ymat_train)
# 2. build XX matrix
p <- ncol(Zmat)
W <- adj.mt/rowSums(adj.mt)
W[rowSums(adj.mt)==0,] = 0
# 3. estimate
# (2) est
# GNAR_summary = Cluster.NAR(Ymat_train, W, Zmat, K = 5, method="complete", seed = n_test)
# Theta = t(GNAR_summary$theta)
# Sigma2 <- (GNAR_summary$sigma)^2
K = 5
GNAR_summary = Cluster.NAR(Ymat_train, W, Zmat, K = 5, method="complete", seed = n_test)
Theta = GNAR_summary$theta
Sigma2 = (GNAR_summary$sigma)^2
p_values_gnar = matrix(0, nrow = K, ncol = p+3)
for (kk in 1:K) {
p_values_gnar[kk, ] = (1 - pnorm(abs(Theta[kk, ])/sqrt(diag(GNAR_summary$cov[[kk]]))))*2
}
View(p_values_gnar)
write.csv(p_values_gnar, "./report/gnar_p_values.csv", row.names = F)
write.csv(round(p_values_gnar, 4), "./report/gnar_p_clean.csv", row.names = F)
setwd("~/Desktop/renyimeng/复旦项目/GAGNAR/GAGNAR_code_JBES/case_study/city")
source("./code/gagnar.R")
source("./code/Dahl.R")
source("./code/LPML_VAR.R")
source("./code/GNAR_code-master/estimator.R")
source("./code/real_estimator.R")
# =========
# load data
# =========
load("./city_data/Ymat.rda")
load("./city_data/Xmat.rda")
load("./city_data/Adjmat.rda")
load("./city_data/dmat.rda")  # d.matrix
cov_scale <- apply(coviriates, 2, rescale)  # normalize to [0,1]
NN = nrow(Ymat)
Zmat = cov_scale[(nrow(cov_scale) - NN+1):nrow(cov_scale),]
# =========
# experiment setting
# =========
train_window = 12
test_window = 12
n_window = 1
train_start = 5
n_test = 1
flag = TRUE
test_days = NULL
pred_rmse = matrix(0, nrow = 7, ncol = 100)
p_value = matrix(0, nrow = 7, ncol = p+3)
# basic setting & tuning param
niterations <- 1500 # number of iterations for MCMC
initNClusters <- 10
burnin <- 500 # number of burnin iterations for MCMC
h <- c(0,2) # crp and optimal h
# h <- c(seq(0,2,0.2),3,4,5)
alpha <- c(1)
hyperpara <- expand.grid(h = h, alpha = alpha)
train_end = train_start + train_window - 1
test_start = train_start + 1
test_end = test_start + test_window - 1
Ymat_train <- Ymat[,(train_start:train_end)]
Ymat_test <- Ymat[,((test_start-1):test_end)]  # use the last of trainset as start point
Ymat_train <- t(Ymat_train)  # T by N
Ymat_test <- t(Ymat_test)
N = ncol(Ymat_train)
TT = nrow(Ymat_train)
# 2. build X matrix
p <- ncol(Zmat)
X_cov <- array(0, dim = c(train_window, N, (p+3)))  # T by N by p
for (t in 1:train_window) {
X_cov[t,,1] <- 1  # constant
X_cov[t,,2] <- 0  # network effect
X_cov[t,,3] <- 0  # momentum effect
X_cov[t,,4:(p+3)] <- Zmat
}
W <- Adjmat/rowSums(Adjmat)
W[rowSums(Adjmat)==0,] = 0
for (t in 2:train_window) {
X_cov[t,,2] <- W %*% Ymat_train[(t-1),]  # network effect
X_cov[t,,3] <- Ymat_train[(t-1),]  # network effect
}
# 3. estimate
# (1) initialize
a0 <- 0.01
b0 <- 0.01
tau0 <- rep(0, p + 3)
sigma0 <- diag(100, p + 3)
# (2) est
real_res <- runReal(Ymat_train, X_cov, d.matrix, hyperpara, niterations,
a0, b0, tau0, sigma0, initNClusters, verbose = T)
# save(real_res, file = "./report/city_res.rda")
# besth_ind <- which.max(unlist(lapply(real_res, function(x){x$LPML})))
besth_ind <- 2  # index of the optimal h
best_h <- real_res[[besth_ind]]$h
ZZ_GAGNAR <- real_res[[besth_ind]]$Dahlout$zout %>% as.factor()
ZZ1_GAGNAR <- model.matrix( ~ ZZ - 1)  # N*K
ZZ_crp <- real_res[[1]]$Dahlout$zout %>% as.factor()
ZZ1_crp <- model.matrix( ~ ZZ_crp - 1)  # N*K
# ===== GAGNAR & CRP =====
ZZ_GAGNAR = load("./report/city_est_label.rda")
ZZ1_GAGNAR <- model.matrix( ~ ZZ_best- 1)  # N*K
load("./report/city_est_label_crp.rda")
ZZ1_crp <- model.matrix( ~ ZZ_crp - 1)  # N*K
# ===== GNAR =====
# 1. split train and test set
Ymat_train <- Ymat[,(train_start:train_end)]
Ymat_test <- Ymat[,((test_start-1):test_end)]  # use the last of trainset as start point
TT = ncol(Ymat_train)
N = nrow(Ymat_train)
# 2. build X matrix
p <- ncol(Zmat)
W <- Adjmat/rowSums(Adjmat)
W[rowSums(Adjmat)==0,] = 0
# 3. estimate
# (2) est
K = 4
GNAR_summary = Cluster.NAR(Ymat_train, W, Zmat, K = 4, method="kmeans", seed = n_test)
ind = order(GNAR_summary$alpha)
group_cl = order(ind)[GNAR_summary$group]
ZZ <- group_cl %>% as.factor()
ZZ1_GNAR <- model.matrix( ~ ZZ - 1)  # N*K
ZZ
# ===== 对应城市名 =====
dijishiID <- read.csv("./city_data/dijishiID.csv")
rownames(Adjmat)
# ===== GAGNAR & CRP =====
load("./report/city_est_label.rda")
ZZ_gnar <- group_cl %>% as.factor()
dijishiID$市[which(as.character(dijishiID$市代码) %in% rownames(Adjmat)[which(ZZ_best == 1)])]
dijishiID$市[which(as.character(dijishiID$市代码) %in% rownames(Adjmat)[which(ZZ_crp == 1)])]
dijishiID$市[which(as.character(dijishiID$市代码) %in% rownames(Adjmat)[which(ZZ_gnar == 1)])]
table(dijishiID$省[which(as.character(dijishiID$市代码) %in% rownames(Adjmat)[which(ZZ_best == 1)])]) %>% sort(decreasing = T)
table(dijishiID$省[which(as.character(dijishiID$市代码) %in% rownames(Adjmat)[which(ZZ_crp == 1)])]) %>% sort(decreasing = T)
table(dijishiID$省[which(as.character(dijishiID$市代码) %in% rownames(Adjmat)[which(ZZ_gnar == 1)])]) %>% sort(decreasing = T)
table(dijishiID$省[which(as.character(dijishiID$市代码) %in% rownames(Adjmat)[which(ZZ_gnar == 2)])]) %>% sort(decreasing = T)
table(dijishiID$省[which(as.character(dijishiID$市代码) %in% rownames(Adjmat)[which(ZZ_gnar == 3)])]) %>% sort(decreasing = T)
table(dijishiID$省[which(as.character(dijishiID$市代码) %in% rownames(Adjmat)[which(ZZ_gnar == 4)])]) %>% sort(decreasing = T)
save(ZZ_gnar, file = "./report/city_est_label_gnar.rda")
setwd("~/Desktop/renyimeng/复旦项目/GAGNAR/GAGNAR_code_JBES/case_study/stock")
setwd("../stock/")
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
try(sapply(pkg, require, character.only = TRUE), silent = TRUE)
}
packages <- c("scales", "igraph", "mvtnorm", "MCMCpack", "parallel", "mclust", "plyr")
ipak(packages)
source("./code/gagnar.R")
source("./code/Dahl.R")
source("./code/LPML_VAR.R")
source("./code/GNAR_code-master/estimator.R")
source("./code/real_estimator.R")
# =========
# =========
# load data
# =========
load("./city_data/Ymat.rda")
load("./city_data/Xmat.rda")
load("./city_data/Adjmat.rda")
load("./stock_data/Ymat_top.rda")
load("./stock_data/Zmat_top.rda")
load("./stock_data/Adjmat_top.rda")
cat("network density is", sum(adj.mt)/(nrow(adj.mt)^2 - nrow(adj.mt)), "\n")
load("./stock_data/dmat_top.rda")  # d.matrix
Zmat <- scale(Zmat)
train_window = 40
test_window = 6
n_window = 1  # rolling window size
train_start = 1
n_test = 1
flag = TRUE
test_days = NULL
train_end = train_start + train_window - 1
test_start = train_end
test_end = test_start + test_window
# ===== GAGNAR & CRP =====
load("./report/stock_est_label.rda")  # ZZ_best
ZZ1_GAGNAR <- model.matrix( ~ ZZ_best- 1)  # N*K
load("./report/stock_est_label_crp.rda")  # ZZ_crp
ZZ1_crp <- model.matrix( ~ ZZ_crp - 1)  # N*K
# ===== GNAR =====
# 1. split train and test set
Ymat_train <- Ymat[,(train_start:train_end)]
Ymat_test <- Ymat[,(test_start:test_end)]  # use the last of trainset as start point
TT = ncol(Ymat_train)
N = nrow(Ymat_train)
# 2. build XX matrix
p <- ncol(Zmat)
W <- adj.mt/rowSums(adj.mt)
W[rowSums(adj.mt)==0,] = 0
# 3. estimate
# (2) est
K = 5
GNAR_summary = Cluster.NAR(Ymat_train, W, Zmat, K = 5, method="complete", seed = n_test)
ind = order(GNAR_summary$alpha)
group_cl = order(ind)[GNAR_summary$group]
ZZ_gnar <- group_cl %>% as.factor()
ZZ1_GNAR <- model.matrix( ~ ZZ_gnar - 1)  # N*K
save(ZZ_gnar, file = "./report/stock_est_label_gnar.rda")
# ===== 对应股票 =====
load("./stock_data/casestudy_stock_names_top.rda")
# ===== 对应股票 =====
library(readxl)
company_data <- read_excel("./stock_data/TRD_Co.xlsx")
company_data$Stkcd <- as.numeric(company_data$Stkcd)
stock_type <- company_data$Nindnme[which(company_data$Stkcd %in% amat_id_5)]
sort(table(stock_type[ZZ_best == 1]), decreasing = T)[1:5]
sort(table(stock_type[ZZ_crp == 1]), decreasing = T)[1:5]
sort(table(stock_type[ZZ_gnar == 1]), decreasing = T)[1:5]
sort(table(stock_type[ZZ_crp == 2]), decreasing = T)[1:5]
sort(table(stock_type[ZZ_gnar == 2]), decreasing = T)[1:5]
sort(table(stock_type[ZZ_crp == 1]), decreasing = T)[1:5]
sort(table(stock_type[ZZ_crp == 2]), decreasing = T)[1:5]
sort(table(stock_type[ZZ_crp == 3]), decreasing = T)[1:5]
sort(table(stock_type[ZZ_crp == 4]), decreasing = T)[1:5]
sort(table(stock_type[ZZ_gnar == 1]), decreasing = T)[1:5]
sort(table(stock_type[ZZ_gnar == 2]), decreasing = T)[1:5]
sort(table(stock_type[ZZ_gnar == 3]), decreasing = T)[1:5]
sort(table(stock_type[ZZ_gnar == 4]), decreasing = T)[1:5]
sort(table(stock_type[ZZ_gnar == 5]), decreasing = T)[1:5]
